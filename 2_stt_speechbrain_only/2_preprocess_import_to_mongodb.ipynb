{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18c2d46e-fc7d-4737-babc-ff3099b75491",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ---------- Essentials: copy existing DB docs, then import your JSON transcripts ----------\n",
    "\n",
    "from pathlib import Path\n",
    "from datetime import datetime\n",
    "import json\n",
    "from pymongo import MongoClient, InsertOne, UpdateOne\n",
    "\n",
    "# --- 0) Config (adjust to your setup) ---\n",
    "MONGO_URI  = \"mongodb://localhost:27018/\"   # your Mongo connection\n",
    "DB_NAME    = \"transcriptions\"\n",
    "SRC_COL    = \"transcripts\"\n",
    "DST_COL    = \"transcripts_denis\"\n",
    "\n",
    "# Root directory where your JSON files are stored (e.g., results_<timestamp> folders)\n",
    "# Example: Path.home() / \"stanic_audio\"\n",
    "JSON_ROOT  = Path.home() / \"stanic_audio\"\n",
    "\n",
    "MODEL_TAG  = \"speechbrain_whisper_rescuespeech\"  # consistent model tag for traceability\n",
    "\n",
    "# --- 1) Connect to MongoDB ---\n",
    "client = MongoClient(MONGO_URI)\n",
    "db = client[DB_NAME]\n",
    "src = db[SRC_COL]\n",
    "dst = db[DST_COL]\n",
    "\n",
    "# Make sure we can upsert on filenames quickly\n",
    "# (unique index prevents duplicates if you re-run this script)\n",
    "try:\n",
    "    dst.create_index(\"filename\", unique=True)\n",
    "except Exception:\n",
    "    pass  # index may already exist; ignore\n",
    "\n",
    "# --- 2) Copy all existing docs from `transcripts` -> `transcripts_denis` (idempotent) ---\n",
    "# We do not drop; we perform blind inserts to keep it simple.\n",
    "# If a doc with the same _id exists, it will error. To avoid that, we remove _id on copy.\n",
    "batch = []\n",
    "BATCH_SIZE = 1000\n",
    "\n",
    "for doc in src.find({}, projection={\"_id\": False}):\n",
    "    batch.append(InsertOne(doc))\n",
    "    if len(batch) >= BATCH_SIZE:\n",
    "        dst.bulk_write(batch, ordered=False)\n",
    "        batch.clear()\n",
    "\n",
    "if batch:\n",
    "    dst.bulk_write(batch, ordered=False)\n",
    "\n",
    "print(\"Copied all existing documents from 'transcripts' to 'transcripts_denis'.\")\n",
    "\n",
    "# --- 3) Load your JSON transcript files and upsert into `transcripts_denis` ---\n",
    "# We search recursively for *.json under JSON_ROOT (e.g., .../results_<timestamp>/*.json)\n",
    "json_files = sorted(JSON_ROOT.rglob(\"*.json\"))\n",
    "\n",
    "for jpath in json_files:\n",
    "    # Skip non-files (just in case)\n",
    "    if not jpath.is_file():\n",
    "        continue\n",
    "\n",
    "    # Read JSON: the file contains a list of segments [{start, end, text, words}, ...]\n",
    "    with jpath.open(\"r\", encoding=\"utf-8\") as f:\n",
    "        try:\n",
    "            segments = json.load(f)\n",
    "        except json.JSONDecodeError:\n",
    "            # Minimal: skip unreadable JSON; no manual checkups requested\n",
    "            continue\n",
    "\n",
    "    # Prepare the document we store\n",
    "    # Key choice: we upsert by filename to keep imports idempotent across runs\n",
    "    doc = {\n",
    "        \"filename\": jpath.name,\n",
    "        \"filepath\": str(jpath),\n",
    "        \"model\": MODEL_TAG,\n",
    "        \"ingested_at\": datetime.utcnow(),\n",
    "        \"segments\": segments\n",
    "    }\n",
    "\n",
    "    # Upsert: replace/set by unique filename\n",
    "    dst.update_one(\n",
    "        {\"filename\": jpath.name},\n",
    "        {\"$set\": doc},\n",
    "        upsert=True\n",
    "    )\n",
    "\n",
    "print(f\"Imported/updated {len(json_files)} JSON files into 'transcripts_denis'.\")\n",
    "print(\"âœ… Done.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23ea90d7-8bf8-47fe-bfab-d37243e97d63",
   "metadata": {},
   "outputs": [],
   "source": [
    "# DONE"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "stanic eval",
   "language": "python",
   "name": "stanic-eval"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
