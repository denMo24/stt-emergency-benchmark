{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6fb49ff3-3e29-4aa7-b669-04fa59ac3376",
   "metadata": {
    "tags": []
   },
   "source": [
    "LEX OLS "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe6dcafc-38ca-4be3-b481-b9b1013d0e31",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Prep"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41a086b8-095d-4ecd-b1ed-5ee5bb99e820",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1) Imports & MongoDB-Verbindung\n",
    "from pymongo import MongoClient\n",
    "import pandas as pd\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "\n",
    "# Verbinden und Collection auswählen\n",
    "client = MongoClient(\"mongodb://localhost:27018/\")\n",
    "db     = client[\"transcriptions\"]\n",
    "coll   = db[\"transcripts_denis\"]\n",
    "\n",
    "# Alle Dokumente (ohne manuell ausgesperrte)\n",
    "docs = list(coll.find({\"excludeGeneral\": 0}))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b2dd64b-f2e0-455f-a91b-8d5f6dd01e46",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2) TF-IDF auf gesamten Korpus fitten\n",
    "# Wir brauchen globale IDF-Werte, also fitten wir auf ALLE Vorverarbeitungen:\n",
    "lex_hyps = [doc[\"text_lex_denis\"] for doc in docs]\n",
    "lex_refs = [doc[\"src_lex_denis\"] for doc in docs]\n",
    "corpus   = lex_hyps + lex_refs\n",
    "\n",
    "vectorizer    = TfidfVectorizer()\n",
    "tfidf_matrix  = vectorizer.fit_transform(corpus)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87384bed-9196-4220-9654-fa035e792f84",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3) Paarweise Cosine-Ähnlichkeit berechnen und in DataFrame packen\n",
    "rows = []\n",
    "N = len(docs)\n",
    "for i, doc in enumerate(docs):\n",
    "    hyp_vec = tfidf_matrix[i]\n",
    "    ref_vec = tfidf_matrix[i + N]\n",
    "    sim     = cosine_similarity(hyp_vec, ref_vec)[0][0]\n",
    "\n",
    "    rows.append({\n",
    "        \"convoID\":           doc.get(\"convoID\"),\n",
    "        \"ambientVariant\":    doc.get(\"ambientVariant\"),\n",
    "        \"processedVolume\":   doc.get(\"processedVolume\"),\n",
    "        \"technology\":        doc.get(\"technology\"),\n",
    "        \"model\":             doc.get(\"model\"),\n",
    "        \"lex_cosine_sim\":    sim\n",
    "    })\n",
    "\n",
    "df_lex = pd.DataFrame(rows)\n",
    "df_lex.to_csv(\"lexical_cosine_scores_full.csv\", index=False, encoding=\"utf-8-sig\")\n",
    "print(\"Lexical Cosine Similarity scores saved to lexical_cosine_scores_full.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e641154c-59e4-4d25-bb15-6a24f0e4d2d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# %%  \n",
    "# 1) Deskriptive Statistik über alle Dokumente\n",
    "import pandas as pd\n",
    "\n",
    "# CSV einlesen\n",
    "df_lex = pd.read_csv(\"lexical_cosine_scores_full.csv\")\n",
    "\n",
    "# Kennzahlen berechnen\n",
    "overall = df_lex[\"lex_cosine_sim\"].agg([\"mean\", \"median\", \"std\", \"min\", \"max\"])\n",
    "print(\"=== Overall Lexical Cosine Similarity ===\")\n",
    "print(overall, \"\\n\")\n",
    "\n",
    "# CSV speichern (optional)\n",
    "overall.to_frame(name=\"value\").to_csv(\"lex_overall_stats.csv\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7b46483-3e03-4166-ad57-74112de703e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# %%  \n",
    "# 2) Gruppiert nach Technologie & Modell\n",
    "import pandas as pd\n",
    "\n",
    "df_lex = pd.read_csv(\"lexical_cosine_scores_full.csv\")\n",
    "\n",
    "# Gruppieren und Kennzahlen berechnen\n",
    "grouped = df_lex.groupby([\"technology\", \"model\"])[\"lex_cosine_sim\"]\n",
    "stats = grouped.agg([\"mean\", \"median\", \"std\", \"min\", \"max\"]).reset_index()\n",
    "\n",
    "print(\"=== Lexical Cosine by Technology & Model ===\")\n",
    "print(stats)\n",
    "\n",
    "# Als CSV speichern\n",
    "stats.to_csv(\"lex_stats_by_model.csv\", index=False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a3b69624-be63-4d4c-9611-1c8ff4c88e1c",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Descriptive"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f0f819b-588b-4a31-b19f-880ab06e9be5",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import warnings\n",
    "import os\n",
    "from matplotlib.ticker import MultipleLocator\n",
    "\n",
    "warnings.filterwarnings(\"ignore\", category=FutureWarning)\n",
    "warnings.filterwarnings(\"ignore\", category=UserWarning)\n",
    "\n",
    "# 1) Daten laden\n",
    "csv_file = \"lexical_cosine_scores_full.csv\"\n",
    "df = pd.read_csv(csv_file)\n",
    "df[\"system\"] = df[\"technology\"] + \"–\" + df[\"model\"]\n",
    "\n",
    "# 2) Labels mappen\n",
    "label_map = {\n",
    "    \"recapp–gsw-CH_smoothed\":         \"recapp\",\n",
    "    \"vosk–vosk-model-de-0.21\":         \"vosk\",\n",
    "    \"whisper–medium\":                  \"whisper_medium\",\n",
    "    \"whisper–large\":                   \"whisper_large\",\n",
    "    \"whisper–turbo\":                   \"whisper_turbo\",\n",
    "    \"whisper_v2–whisper_rescuespeech\": \"rescuespeech\"\n",
    "}\n",
    "df[\"label\"] = df[\"system\"].map(label_map)\n",
    "\n",
    "# 3) Reihenfolge & Farben\n",
    "order = [lbl for lbl in [\"recapp\",\"vosk\",\"whisper_medium\",\"whisper_large\",\"whisper_turbo\",\"rescuespeech\"]\n",
    "         if lbl in df[\"label\"].unique()]\n",
    "palette = {\n",
    "    \"recapp\":         \"#c6c6c6\",\n",
    "    \"vosk\":           \"#aad9e6\",\n",
    "    \"whisper_medium\": \"#7bc96f\",\n",
    "    \"whisper_large\":  \"#2ca02c\",\n",
    "    \"whisper_turbo\":  \"#1f7a1f\",\n",
    "    \"rescuespeech\":   \"#fdb064\"\n",
    "}\n",
    "\n",
    "# 4) Plot‑Style\n",
    "sns.set(style=\"whitegrid\", font_scale=1.0)\n",
    "\n",
    "# 5) Figure & Axes absolut setzen\n",
    "fig = plt.figure(figsize=(3, 3))               # Breite 3\", Höhe 4\"\n",
    "ax = fig.add_axes([0.18, 0.18, 0.75, 0.75])     # Position und Größe des Plot-Bereichs\n",
    "\n",
    "# 6) Boxplot zeichnen\n",
    "flierprops = dict(marker='o', color='black', markersize=4)\n",
    "sns.boxplot(\n",
    "    data=df,\n",
    "    x=\"label\", y=\"lex_cosine_sim\",\n",
    "    order=order, palette=palette,\n",
    "    flierprops=flierprops,\n",
    "    ax=ax,\n",
    "    width=0.4\n",
    ")\n",
    "\n",
    "# 7) Titel, Achsenbeschriftungen & fixe Y‑Skala\n",
    "ax.set_title(\"TF-IDF Cosine Sim. per Model\", pad=12)\n",
    "ax.set_xlabel(\"\")  # untere Beschriftung entfernt\n",
    "ax.set_ylabel(\"Cosine Similarity\", labelpad=8)\n",
    "ax.set_ylim(0, 1)\n",
    "\n",
    "# 8) Einheitliche Grid‑Linien\n",
    "ax.yaxis.set_major_locator(MultipleLocator(0.1))\n",
    "ax.grid(axis=\"y\", which=\"major\", linestyle=\"--\", linewidth=0.5)\n",
    "\n",
    "# 9) X‑Ticks rotieren\n",
    "ax.set_xticklabels(order, rotation=45, ha=\"right\", fontsize=10)\n",
    "\n",
    "# 10) Ergebnis‑Ordner\n",
    "output_dir = os.path.join(os.path.dirname(csv_file), \"results_for_paper\")\n",
    "os.makedirs(output_dir, exist_ok=True)\n",
    "\n",
    "# 11) Speichern ohne tight_layout\n",
    "output_png = os.path.join(output_dir, \"tfidf_cosine_boxplot_fixed.png\")\n",
    "fig.savefig(output_png, format=\"png\", dpi=300)\n",
    "\n",
    "# 12) Anzeige und Pfad\n",
    "plt.show()\n",
    "print(f\"Plot saved at: {output_png}\")\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0126382-2799-468c-b667-3206dd8fbe7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import warnings\n",
    "import os\n",
    "from matplotlib.ticker import MultipleLocator\n",
    "\n",
    "warnings.filterwarnings(\"ignore\", category=FutureWarning)\n",
    "warnings.filterwarnings(\"ignore\", category=UserWarning)\n",
    "\n",
    "# 1) Daten laden\n",
    "csv_file = \"lexical_cosine_scores_full.csv\"\n",
    "df = pd.read_csv(csv_file)\n",
    "df[\"system\"] = df[\"technology\"] + \"–\" + df[\"model\"]\n",
    "\n",
    "# 2) Labels mappen\n",
    "label_map = {\n",
    "    \"recapp–gsw-CH_smoothed\":         \"recapp\",\n",
    "    \"vosk–vosk-model-de-0.21\":         \"vosk\",\n",
    "    \"whisper–medium\":                  \"whisper_medium\",\n",
    "    \"whisper–large\":                   \"whisper_large\",\n",
    "    \"whisper–turbo\":                   \"whisper_turbo\",\n",
    "    \"whisper_v2–whisper_rescuespeech\": \"rescuespeech\"\n",
    "}\n",
    "df[\"label\"] = df[\"system\"].map(label_map)\n",
    "\n",
    "# 3) Reihenfolge & Farben\n",
    "order = [lbl for lbl in [\"recapp\",\"vosk\",\"whisper_medium\",\"whisper_large\",\"whisper_turbo\",\"rescuespeech\"]\n",
    "         if lbl in df[\"label\"].unique()]\n",
    "palette = {\n",
    "    \"recapp\":         \"#c6c6c6\",\n",
    "    \"vosk\":           \"#aad9e6\",\n",
    "    \"whisper_medium\": \"#7bc96f\",\n",
    "    \"whisper_large\":  \"#2ca02c\",\n",
    "    \"whisper_turbo\":  \"#1f7a1f\",\n",
    "    \"rescuespeech\":   \"#fdb064\"\n",
    "}\n",
    "\n",
    "# 4) Plot‑Style\n",
    "sns.set(style=\"whitegrid\", font_scale=1.0)\n",
    "\n",
    "# 5) Figure & Axes absolut setzen\n",
    "fig = plt.figure(figsize=(3, 3))\n",
    "# exakt gleiche Ränder wie beim finalen WER-Plot\n",
    "ax = fig.add_axes([0.12, 0.18, 0.80, 0.75])\n",
    "\n",
    "# 6) Boxplot zeichnen\n",
    "flierprops = dict(marker='o', color='black', markersize=4)\n",
    "sns.boxplot(\n",
    "    data=df,\n",
    "    x=\"label\", y=\"lex_cosine_sim\",\n",
    "    order=order, palette=palette,\n",
    "    flierprops=flierprops,\n",
    "    ax=ax,\n",
    "    width=0.4\n",
    ")\n",
    "\n",
    "# 7) Titel, Achsenbeschriftungen & fixe Y‑Skala\n",
    "ax.set_title(\"TF-IDF Cosine Sim. per Model\", pad=12)\n",
    "ax.set_xlabel(\"\")  \n",
    "ax.set_ylabel(\"Cosine Similarity\", labelpad=8)\n",
    "ax.set_ylim(0, 1)\n",
    "\n",
    "# 8) Einheitliche Grid‑Linien\n",
    "ax.yaxis.set_major_locator(MultipleLocator(0.1))\n",
    "ax.grid(axis=\"y\", which=\"major\", linestyle=\"--\", linewidth=0.5)\n",
    "\n",
    "# 9) X‑Ticks rotieren\n",
    "ax.set_xticklabels(order, rotation=45, ha=\"right\", fontsize=10)\n",
    "\n",
    "# 10) Ergebnis‑Ordner & Speichern\n",
    "output_dir = os.path.join(os.path.dirname(csv_file), \"results_for_paper\")\n",
    "os.makedirs(output_dir, exist_ok=True)\n",
    "output_png = os.path.join(output_dir, \"tfidf_cosine_boxplot_fixed.png\")\n",
    "\n",
    "# Hier wird bbox_inches='tight' verwendet, um Ränder exakt zu erhalten\n",
    "fig.savefig(output_png, format=\"png\", dpi=300, bbox_inches='tight', pad_inches=0.1)\n",
    "\n",
    "# 11) Anzeige & Pfad\n",
    "plt.show()\n",
    "print(f\"Plot saved at: {output_png}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bfe35af5-25be-4945-abda-1b1279214542",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import warnings\n",
    "import os\n",
    "from matplotlib.ticker import MultipleLocator\n",
    "\n",
    "warnings.filterwarnings(\"ignore\", category=FutureWarning)\n",
    "warnings.filterwarnings(\"ignore\", category=UserWarning)\n",
    "\n",
    "# 1) Daten laden\n",
    "csv_file = \"lexical_cosine_scores_full.csv\"\n",
    "df = pd.read_csv(csv_file)\n",
    "df[\"system\"] = df[\"technology\"] + \"–\" + df[\"model\"]\n",
    "\n",
    "# 2) Labels mappen\n",
    "label_map = {\n",
    "    \"recapp–gsw-CH_smoothed\":         \"recapp\",\n",
    "    \"vosk–vosk-model-de-0.21\":         \"vosk\",\n",
    "    \"whisper–medium\":                  \"whisper_medium\",\n",
    "    \"whisper–large\":                   \"whisper_large\",\n",
    "    \"whisper–turbo\":                   \"whisper_turbo\",\n",
    "    \"whisper_v2–whisper_rescuespeech\": \"rescuespeech\"\n",
    "}\n",
    "df[\"label\"] = df[\"system\"].map(label_map)\n",
    "\n",
    "# 3) Reihenfolge & Farben\n",
    "order = [\"recapp\",\"vosk\",\"whisper_medium\",\"whisper_large\",\"whisper_turbo\",\"rescuespeech\"]\n",
    "palette = {\n",
    "    \"recapp\":         \"#c6c6c6\",\n",
    "    \"vosk\":           \"#aad9e6\",\n",
    "    \"whisper_medium\": \"#7bc96f\",\n",
    "    \"whisper_large\":  \"#2ca02c\",\n",
    "    \"whisper_turbo\":  \"#1f7a1f\",\n",
    "    \"rescuespeech\":   \"#fdb064\"\n",
    "}\n",
    "\n",
    "# 4) Fest definierte dBFS- & Ambient-Varianten\n",
    "volumes = [\"-35dBFS\",\"-30dBFS\",\"-25dBFS\",\"-20dBFS\",\"-15dBFS\"]\n",
    "# Zuordnungen zu Anzeige-Text mit SNR in Klammern\n",
    "vol_labels = {\n",
    "    \"-35dBFS\": \"-35 dBFS\\n(SNR: 18 dB)\",\n",
    "    \"-30dBFS\": \"-30 dBFS\\n(SNR: 13 dB)\",\n",
    "    \"-25dBFS\": \"-25 dBFS\\n(SNR: 8 dB)\",\n",
    "    \"-20dBFS\": \"-20 dBFS\\n(SNR: 3 dB)\",\n",
    "    \"-15dBFS\": \"-15 dBFS\\n(SNR: –2 dB)\"\n",
    "}\n",
    "ambients = sorted(df[\"ambientVariant\"].unique())\n",
    "\n",
    "sns.set(style=\"whitegrid\", font_scale=1.0)\n",
    "\n",
    "# 5) FacetGrid mit fixierter Reihenfolge\n",
    "g = sns.catplot(\n",
    "    data=df,\n",
    "    x=\"label\", y=\"lex_cosine_sim\",\n",
    "    row=\"ambientVariant\", col=\"processedVolume\",\n",
    "    kind=\"box\",\n",
    "    order=order, palette=palette,\n",
    "    height=3, aspect=1,\n",
    "    sharey=True, margin_titles=True, legend=False,\n",
    "    col_order=volumes,\n",
    "    row_order=ambients\n",
    ")\n",
    "\n",
    "# 6) Entferne Default-Titles\n",
    "g.set_titles(row_template=\"\", col_template=\"\")\n",
    "\n",
    "# 7) Abstände und Supertitel setzen\n",
    "g.fig.subplots_adjust(\n",
    "    top=0.85,    # Raum für Haupttitel + Noise Volume\n",
    "    left=0.18,   # Raum für Ambient-Labels\n",
    "    right=0.98,\n",
    "    hspace=0.35,\n",
    "    wspace=0.25\n",
    ")\n",
    "g.fig.suptitle(\"TF-IDF Cosine Similarity\", fontsize=16)\n",
    "\n",
    "# 8) Noise Volume Label oberhalb der Spalten\n",
    "g.fig.text(\n",
    "    0.50, 0.92,           # y etwas tiefer als Haupttitel\n",
    "    \"Noise Volume\",\n",
    "    ha=\"center\", va=\"center\",\n",
    "    fontsize=12, fontweight=\"bold\"\n",
    ")\n",
    "\n",
    "# 9) Facet-Überschriften (Volume mit SNR) manuell setzen\n",
    "for col_idx, vol in enumerate(volumes):\n",
    "    # erstes Achsen-Objekt jeder Spalte\n",
    "    ax = g.axes[0][col_idx]\n",
    "    ax.set_title(vol_labels[vol], pad=8)\n",
    "\n",
    "# 10) Feintuning jeder Facet-Achse\n",
    "for row_idx, amb in enumerate(ambients):\n",
    "    for col_idx, vol in enumerate(volumes):\n",
    "        ax = g.axes[row_idx][col_idx]\n",
    "        ax.set_ylim(0, 1)\n",
    "        ax.yaxis.set_major_locator(MultipleLocator(0.1))\n",
    "        ax.grid(axis=\"y\", which=\"major\", linestyle=\"--\", linewidth=0.5)\n",
    "        ax.set_xticklabels(order, rotation=90, ha=\"center\", fontsize=10)\n",
    "        ax.set_xlabel(\"\")  # kein X-Label\n",
    "        ax.set_ylabel(\"\")  # kein Y-Label in Facets\n",
    "\n",
    "    # manuelles Ambient-Label links außen\n",
    "    ax0 = g.axes[row_idx][0]\n",
    "    ax0.text(\n",
    "        -0.30, 0.5, amb,     # weiter nach links verschoben\n",
    "        ha=\"center\", va=\"center\",\n",
    "        rotation=90, transform=ax0.transAxes,\n",
    "        fontsize=12, fontweight=\"bold\"\n",
    "    )\n",
    "\n",
    "# 11) Ein einziges Y‑Achsen-Label links außen\n",
    "g.fig.text(\n",
    "    0.05, 0.5,\n",
    "    \"Noise Type\",\n",
    "    ha=\"center\", va=\"center\",\n",
    "    rotation=\"vertical\",\n",
    "    fontsize=12,\n",
    "    fontweight=\"bold\"\n",
    ")\n",
    "\n",
    "# 12) Ergebnis-Ordner anlegen & speichern\n",
    "output_dir = os.path.join(os.path.dirname(csv_file), \"results_for_paper\")\n",
    "os.makedirs(output_dir, exist_ok=True)\n",
    "output_png = os.path.join(output_dir, \"tfidf_cosine_facetgrid.png\")\n",
    "g.fig.savefig(output_png, format=\"png\", dpi=300)\n",
    "\n",
    "# 13) Anzeige & Pfad\n",
    "plt.show()\n",
    "print(f\"Plot saved at: {output_png}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f78f680-ef8c-4a9a-b09f-741aec1bfc65",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import itertools\n",
    "from scipy.stats import shapiro\n",
    "\n",
    "# CSV mit Lexical Cosine laden\n",
    "df = pd.read_csv(\"lexical_cosine_scores_full.csv\")\n",
    "df[\"system\"] = df[\"technology\"] + \"_\" + df[\"model\"]\n",
    "\n",
    "# Pivot in breites Format\n",
    "wide = df.pivot_table(\n",
    "    index=[\"convoID\", \"ambientVariant\", \"processedVolume\"],\n",
    "    columns=\"system\",\n",
    "    values=\"lex_cosine_sim\"\n",
    ")\n",
    "\n",
    "# Shapiro-Ergebnisse sammeln\n",
    "results = []\n",
    "systems = [col for col in wide.columns if wide[col].notna().any()]\n",
    "for a, b in itertools.combinations(systems, 2):\n",
    "    x = wide[a].dropna()\n",
    "    y = wide[b].dropna()\n",
    "    common = x.index.intersection(y.index)\n",
    "    if len(common) < 30:\n",
    "        continue\n",
    "    diff = x.loc[common] - y.loc[common]\n",
    "    W, p_norm = shapiro(diff)\n",
    "    results.append({\n",
    "        \"System A\":      a,\n",
    "        \"System B\":      b,\n",
    "        \"Shapiro W\":     round(W, 3),\n",
    "        \"Shapiro p\":     round(p_norm, 6),\n",
    "        \"Normal? (p>0.05)\": p_norm > 0.05\n",
    "    })\n",
    "\n",
    "res_df = pd.DataFrame(results)\n",
    "\n",
    "# Nur die Verletzungen (Normal? = False) anzeigen\n",
    "violations = res_df[res_df[\"Normal? (p>0.05)\"] == False]\n",
    "print(\"=== Paare mit Normalitäts-Verletzung (Shapiro p ≤ 0.05) ===\")\n",
    "print(violations.to_string(index=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9be39f9e-f994-45ee-bbf0-19f579f2988b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# %%  \n",
    "# Signifikanz- und Effektstärken-Tests für Lexical Cosine Similarity\n",
    "import pandas as pd\n",
    "import itertools\n",
    "from scipy.stats import shapiro, ttest_rel, wilcoxon\n",
    "\n",
    "# 1) CSV laden und System-Label bauen\n",
    "df = pd.read_csv(\"lexical_cosine_scores_full.csv\")\n",
    "df[\"system\"] = df[\"technology\"] + \"_\" + df[\"model\"]\n",
    "\n",
    "# 2) Pivotieren\n",
    "wide = df.pivot_table(\n",
    "    index=[\"convoID\", \"ambientVariant\", \"processedVolume\"],\n",
    "    columns=\"system\",\n",
    "    values=\"lex_cosine_sim\"\n",
    ")\n",
    "\n",
    "# 3) Effektstärke-Funktion\n",
    "def cohens_d_paired(x, y):\n",
    "    diff = x - y\n",
    "    return diff.mean() / diff.std(ddof=1)\n",
    "\n",
    "# 4) Tests über alle Systempaare\n",
    "results = []\n",
    "systems = [col for col in wide.columns if wide[col].notna().any()]\n",
    "for a, b in itertools.combinations(systems, 2):\n",
    "    x = wide[a].dropna()\n",
    "    y = wide[b].dropna()\n",
    "    common = x.index.intersection(y.index)\n",
    "    if len(common) < 30:\n",
    "        continue  # nur Paare mit ausreichend gemeinsamen Beobachtungen\n",
    "\n",
    "    diff = x.loc[common] - y.loc[common]\n",
    "    W, p_norm = shapiro(diff)\n",
    "\n",
    "    if p_norm > 0.05:\n",
    "        stat, p_val = ttest_rel(x.loc[common], y.loc[common])\n",
    "        test_name = \"paired t-Test\"\n",
    "    else:\n",
    "        stat, p_val = wilcoxon(x.loc[common], y.loc[common])\n",
    "        test_name = \"Wilcoxon\"\n",
    "\n",
    "    d = cohens_d_paired(x.loc[common], y.loc[common])\n",
    "    results.append({\n",
    "        \"System A\": a,\n",
    "        \"System B\": b,\n",
    "        \"Test\": test_name,\n",
    "        \"p-value\": p_val,\n",
    "        \"Cohen's d\": d\n",
    "    })\n",
    "\n",
    "# 5) DataFrame & CSV\n",
    "df_results = pd.DataFrame(results)\n",
    "df_results.to_csv(\"lex_significance_effect_sizes.csv\", index=False, encoding=\"utf-8-sig\")\n",
    "display(df_results)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f1b7fda-8339-45e9-965a-0bcd7fdfdf34",
   "metadata": {},
   "source": [
    "# Inference"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef7e28c2-1e28-48c8-b07c-ab0c04ff20a4",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Check Multicolinearity\n",
    "\n",
    "VIF ≈ 1: praktisch keine Kollinearität\n",
    "\n",
    "1 < VIF < 5: geringe bis moderate Kollinearität, in der Regel unproblematisch\n",
    "\n",
    "VIF ≥ 5 (manche Quellen sagen ≥10): erhöhte Kollinearität, mögliche Probleme bei der Interpretation der Koeffizienten\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5295ccff-6fbc-4832-9f0e-ca2f01531a5c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from statsmodels.stats.outliers_influence import variance_inflation_factor\n",
    "\n",
    "# Design-Matrix des zuletzt gefitteten Models\n",
    "X = ols_sys.model.exog\n",
    "names = ols_sys.model.exog_names\n",
    "\n",
    "vif = pd.DataFrame({\n",
    "    \"variable\": names,\n",
    "    \"VIF\": [variance_inflation_factor(X, i) for i in range(X.shape[1])]\n",
    "})\n",
    "\n",
    "print(vif)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "68653637-f89e-48d9-b728-4df0754c9067",
   "metadata": {},
   "source": [
    "--> VIF: All good"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "417382ae-647d-4dcd-a37e-e9eed2209a85",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import statsmodels.formula.api as smf\n",
    "\n",
    "# 1) Daten laden\n",
    "df = pd.read_csv(\"lexical_cosine_scores_full.csv\")\n",
    "\n",
    "# 2) System-Faktor mit gewünschter Baseline\n",
    "df[\"system\"] = df[\"technology\"] + \"–\" + df[\"model\"]\n",
    "levels = list(df[\"system\"].unique())\n",
    "# Stelle sicher, dass 'recapp–gsw-CH_smoothed' an erster Stelle steht\n",
    "levels.remove(\"recapp–gsw-CH_smoothed\")\n",
    "levels = [\"recapp–gsw-CH_smoothed\"] + levels\n",
    "df[\"system\"] = pd.Categorical(df[\"system\"], categories=levels)\n",
    "\n",
    "# 3) AmbientVariant mit Baseline 'trafficOutside'\n",
    "av = list(df[\"ambientVariant\"].unique())\n",
    "av.remove(\"trafficOutside\")\n",
    "av = [\"trafficOutside\"] + av\n",
    "df[\"ambientVariant\"] = pd.Categorical(df[\"ambientVariant\"], categories=av)\n",
    "\n",
    "# 4) ProcessedVolume mit Baseline '-35dBFS'\n",
    "pv = list(df[\"processedVolume\"].unique())\n",
    "pv.remove(\"-35dBFS\")\n",
    "pv = [\"-35dBFS\"] + pv\n",
    "df[\"processedVolume\"] = pd.Categorical(df[\"processedVolume\"], categories=pv)\n",
    "\n",
    "# 5) Einfaches OLS mit cluster‐robusten SEs\n",
    "formula = \"lex_cosine_sim ~ C(system) + C(ambientVariant) + C(processedVolume)\"\n",
    "ols = smf.ols(formula, data=df).fit()\n",
    "ols_clust = ols.get_robustcov_results(cov_type=\"cluster\", groups=df[\"convoID\"])\n",
    "\n",
    "# 6) Ergebnisse\n",
    "print(ols_clust.summary())\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e0a722c0-fa08-45d6-afd5-0f025d4b7db5",
   "metadata": {},
   "source": [
    "# Saving"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d248aba-2392-453e-b973-685abae3474c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "from statsmodels.stats.outliers_influence import variance_inflation_factor\n",
    "import statsmodels.formula.api as smf\n",
    "\n",
    "# 1) Arbeitsverzeichnis anzeigen\n",
    "cwd = os.getcwd()\n",
    "print(f\"Arbeitsverzeichnis: {cwd}\")\n",
    "\n",
    "# 2) Verzeichnis für den Export erstellen (falls noch nicht vorhanden)\n",
    "export_dir = os.path.join(cwd, \"results_for_paper/\")\n",
    "os.makedirs(export_dir, exist_ok=True)\n",
    "\n",
    "# -----------------------\n",
    "# 3) Daten laden\n",
    "df = pd.read_csv(\"lexical_cosine_scores_full.csv\")\n",
    "\n",
    "# 4) Faktoren mit gewünschter Baseline\n",
    "df[\"system\"] = df[\"technology\"] + \"–\" + df[\"model\"]\n",
    "levels = list(df[\"system\"].unique())\n",
    "if \"recapp–gsw-CH_smoothed\" in levels:\n",
    "    levels.remove(\"recapp–gsw-CH_smoothed\")\n",
    "    levels = [\"recapp–gsw-CH_smoothed\"] + levels\n",
    "    df[\"system\"] = pd.Categorical(df[\"system\"], categories=levels)\n",
    "\n",
    "av = list(df[\"ambientVariant\"].unique())\n",
    "if \"trafficOutside\" in av:\n",
    "    av.remove(\"trafficOutside\")\n",
    "    av = [\"trafficOutside\"] + av\n",
    "    df[\"ambientVariant\"] = pd.Categorical(df[\"ambientVariant\"], categories=av)\n",
    "\n",
    "pv = list(df[\"processedVolume\"].unique())\n",
    "if \"-35dBFS\" in pv:\n",
    "    pv.remove(\"-35dBFS\")\n",
    "    pv = [\"-35dBFS\"] + pv\n",
    "    df[\"processedVolume\"] = pd.Categorical(df[\"processedVolume\"], categories=pv)\n",
    "\n",
    "# -----------------------\n",
    "# 5) OLS-Regression mit cluster‐robusten SEs\n",
    "formula = \"lex_cosine_sim ~ C(system) + C(ambientVariant) + C(processedVolume)\"\n",
    "ols = smf.ols(formula, data=df).fit()\n",
    "ols_clust = ols.get_robustcov_results(cov_type=\"cluster\", groups=df[\"convoID\"])\n",
    "\n",
    "print(\"=== OLS (cluster-robust) ===\")\n",
    "print(ols_clust.summary())\n",
    "\n",
    "# Zusammenfassung in DataFrame\n",
    "summary = ols_clust.summary2()\n",
    "summary_df = summary.tables[1]\n",
    "\n",
    "# Speichern der OLS-Ergebnisse\n",
    "ols_csv = os.path.join(export_dir, \"ols_clust_results_cosine.csv\")\n",
    "summary_df.to_csv(ols_csv)\n",
    "ols_xlsx = os.path.join(export_dir, \"ols_clust_results_cosine.xlsx\")\n",
    "summary_df.to_excel(ols_xlsx)\n",
    "print(f\"OLS-Ergebnisse gespeichert unter:\\n  {ols_csv}\\n  {ols_xlsx}\")\n",
    "\n",
    "# -----------------------\n",
    "# 6) Multikollinearität prüfen (VIF)\n",
    "#    Design-Matrix aus dem gefitteten ols-Objekt\n",
    "X = ols.model.exog\n",
    "names = ols.model.exog_names\n",
    "\n",
    "vif = pd.DataFrame({\n",
    "    \"variable\": names,\n",
    "    \"VIF\": [variance_inflation_factor(X, i) for i in range(X.shape[1])]\n",
    "})\n",
    "\n",
    "print(\"=== VIF ===\")\n",
    "print(vif)\n",
    "\n",
    "# Speichern der VIF-Ergebnisse\n",
    "vif_csv = os.path.join(export_dir, \"vif_results_cosine.csv\")\n",
    "vif.to_csv(vif_csv, index=False)\n",
    "vif_xlsx = os.path.join(export_dir, \"vif_results_cosine.xlsx\")\n",
    "vif.to_excel(vif_xlsx, index=False)\n",
    "print(f\"VIF-Ergebnisse gespeichert unter:\\n  {vif_csv}\\n  {vif_xlsx}\")\n",
    "\n",
    "# -----------------------\n",
    "# 7) Deskriptive Statistiken für TF‑IDF‑Cosine Similarity berechnen\n",
    "grouped_cosine = df.groupby([\"model\", \"technology\"])[\"lex_cosine_sim\"]\n",
    "stats_cosine_df = grouped_cosine.agg([\"mean\", \"median\", \"std\", \"min\", \"max\"]).reset_index()\n",
    "\n",
    "# Speichern der deskriptiven Statistiken\n",
    "cosine_stats_csv = os.path.join(export_dir, \"cosine_stats_by_model.csv\")\n",
    "stats_cosine_df.to_csv(cosine_stats_csv, index=False)\n",
    "cosine_stats_xlsx = os.path.join(export_dir, \"cosine_stats_by_model.xlsx\")\n",
    "stats_cosine_df.to_excel(cosine_stats_xlsx, index=False)\n",
    "print(f\"Deskriptive Statistiken gespeichert unter:\\n  {cosine_stats_csv}\\n  {cosine_stats_xlsx}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "stanic eval",
   "language": "python",
   "name": "stanic-eval"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
