{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Setup\n",
    "To setup this whole Jupyter-Notebook, the following code needs to be executed. It imports the general libraries and sets the utils classes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import sys\n",
    "import json\n",
    "import torch\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from pathlib import Path\n",
    "from utils.logger_handler import Logger\n",
    "\n",
    "SENDING_TO_RECAPP = False\n",
    "SENDING_TO_WHISPER = False\n",
    "SENDING_TO_SPEECHBRAIN = False\n",
    "SENDING_TO_VOSK = True\n",
    "\n",
    "if (SENDING_TO_RECAPP): \n",
    "    from technologies.stt.recapp.recapp import TTSRecapp\n",
    "    # Initialize TTSRecapp Instance\n",
    "    recapp_inst = TTSRecapp()\n",
    "if (SENDING_TO_WHISPER): \n",
    "    from technologies.stt.whisper.whisper import TTSWhisper\n",
    "    # Initialize TTSWhisper Instance\n",
    "    whisper_inst = TTSWhisper()\n",
    "if (SENDING_TO_SPEECHBRAIN): \n",
    "    from technologies.stt.speechbrain.speechbrain import TTSSpeechBrain\n",
    "    # Initialize TTSSpeechBrain Instance\n",
    "    speechbrain_inst = TTSSpeechBrain()\n",
    "if (SENDING_TO_VOSK): \n",
    "    from technologies.stt.vosk.vosk import TTSVosk\n",
    "    # Initialize TTSVosk Instance\n",
    "    vosk_inst = TTSVosk()\n",
    "\n",
    "# Setup Logger\n",
    "logger = Logger()\n",
    "original_stdout = sys.stdout  # Save the original stdout\n",
    "sys.stdout = logger  # Redirect stdout to logger"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Recapp\n",
    "Sending Requests to Recapp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sending all files in \"final_audio\" folder.\n",
    "# Important: Make sure only 345 files are inside, and none are longer than 16min\n",
    "if (SENDING_TO_RECAPP):\n",
    "    for dialog_file in Path(recapp_inst.getSourceFolderPath()).iterdir():\n",
    "        if dialog_file.is_file() and dialog_file.suffix.lower() == \".wav\":\n",
    "            print(\"-----------------------------------\")\n",
    "            print(f\"Sending Request for dialog file: {dialog_file}\")\n",
    "            recapp_inst.sendTranscripitionTask(dialog_file, \"jobs\")\n",
    "            # Wait 2minutes / 120s before sending text request, to prevent overload on server\n",
    "            time.sleep(120)\n",
    "    # Wait 60mins before checking for transkripts\n",
    "    time.sleep(3600)\n",
    "    recapp_inst.checkForUpdatesOnServer()\n",
    "    recapp_inst.checkForPendingTranscriptDownload()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Checking Jobs on Server manually, and then downloading the scripts if there is need for it. Waiting an 10 mins after each execution to let the server process more."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "if (SENDING_TO_RECAPP):\n",
    "    recapp_inst.checkForUpdatesOnServer()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Show all jobs on Recapp server as a diagram to get a quick overview"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "if (SENDING_TO_RECAPP):\n",
    "    jobs = recapp_inst.getAllJobsOnServer(\"jobs\")\n",
    "    data = json.loads(jobs)\n",
    "\n",
    "    df = pd.DataFrame(data)\n",
    "    # Select  the 'id', 'status' and 'created_at' columns\n",
    "    df_selected = df[['id', 'status', 'created_at']]\n",
    "    \n",
    "    # Group by 'status' and count elements\n",
    "    status_counts = df['status'].value_counts()\n",
    "\n",
    "    # Plot the bar chart\n",
    "    plt.figure(figsize=(8, 6))\n",
    "    sns.barplot(x=status_counts.index, y=status_counts.values, hue=status_counts.index, palette=\"viridis\", legend=False)\n",
    "\n",
    "    # Labels and title\n",
    "    plt.xlabel('Status')\n",
    "    plt.ylabel('Count')\n",
    "    plt.title('Jobs on Recapp Server, grouped by Status')\n",
    "\n",
    "    # Show the plot\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Once all files have been transcribed, we need to merge them to prepare them for the metrics."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "recappDone = False\n",
    "if (SENDING_TO_RECAPP and recappDone):\n",
    "    recapp_inst.transferTranscriptsFilesToMongoDB()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Whisper"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "if (SENDING_TO_WHISPER):\n",
    "    # Add models to be used here\n",
    "    models = ['turbo', 'large', 'medium']\n",
    "    if torch.cuda.is_available():\n",
    "        print(f\"CUDA available, using GPU: {torch.cuda.get_device_name(0)}\")\n",
    "        device = \"cuda\"\n",
    "    else:\n",
    "        print(f\"CUDA not available, using CPU.\")\n",
    "        device = \"cpu\"\n",
    "    lng = \"de\"\n",
    "    \n",
    "    # Check if Outputfolder exists\n",
    "    if not Path(whisper_inst.getOutputDirectory()).exists():\n",
    "        print(f\"Transcription-Folder not found. Creating Folder 'transcription' at {whisper_inst.getOutputDirectory()} with 'whisper' in it.\")\n",
    "        Path(whisper_inst.getOutputDirectory()).mkdir(parents=True, exist_ok=True)\n",
    "    \n",
    "    # Start Task for each model  \n",
    "    for cur_model in models:\n",
    "        whisper_inst.transcribeFiles(cur_model, device, lng)\n",
    "        \n",
    "    # Add Transcriptions to Transcript Collection\n",
    "    whisper_inst.transferJSONFilesToMongoDB()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SpeechBrain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "if (SENDING_TO_SPEECHBRAIN):\n",
    "    model = \"whisper_rescuespeech\"\n",
    "    if torch.cuda.is_available():\n",
    "        print(f\"CUDA available, using GPU: {torch.cuda.get_device_name(0)}\")\n",
    "        device = \"cuda\"\n",
    "    else:\n",
    "        print(f\"CUDA not available, using CPU.\")\n",
    "        device = \"cpu\"\n",
    "    lng = \"de\"\n",
    "    speechbrain_inst.transcribeFiles(model, device, lng)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Vosk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if (SENDING_TO_VOSK):\n",
    "    vosk_inst.transcribeFiles()  \n",
    "    vosk_inst.transferJSONFilesToMongoDB()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Change the stdout of sys back to the normal value before closing the logger."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "sys.stdout = original_stdout\n",
    "logger.close()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
